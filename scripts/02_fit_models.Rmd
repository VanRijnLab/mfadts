---
title: "Fit memory models"
author: "Maarten van der Velde"
date: "Last updated: `r Sys.Date()`"
output:
  html_notebook:
    smart: no
    toc: yes
    toc_float: yes
  github_document:
    toc: yes
editor_options: 
  chunk_output_type: inline
---

# Setup

```{r}
library(data.table)
library(purrr)
library(furrr)
library(ggplot2)
library(cowplot)
library(tidyr)

source("00_helper_funs.R")

future::plan("multiprocess", workers = 6) # Set to desired number of cores

set.seed(0)
```


## Model fitting setup

To save time, we can load model fitting results from cache:
```{r}
use_cache <- TRUE
```

Set default parameters for the memory model:
```{r}
model_params <- list(
  s = .5,
  decay = .5,
  h = 1
)
```

Set parameters for splitting the data into windows:
```{r}
n_windows <- c(1:10, 20, 25, 50, 100)
```


## Data setup

```{r}
d_f <- fread(file.path("..", "data", "cogpsych_data_formatted.csv"))
```

Last observation per learning sequence:
```{r}
d_last <- d_f[, .SD[.N], by = id]
setorder(d_last, time_between)
```

Define the time windows for all splits of the data:
```{r}
window_range <- map_dfr(n_windows, function (n_w) {

  d_windows <- copy(d_last)
  
  if (n_w == 1) {
    d_windows[, window := 1]
  } else {
    d_windows[, window := cut(log(time_between), breaks = n_w, labels = FALSE)]
  }
  
  # Get the window range(s)
  window_range <- d_windows[, .(start = min(time_between), end = max(time_between)), by = .(window)]
  window_range[, geom_mean := sqrt(start*end), by = .(window)]
  setorder(window_range, window)
  window_range[, window := window]
  window_range[, n_windows := n_w]

  return (window_range)
})

```


# Fit model

## Optimal retrieval threshold

Find the optimal threshold per window using logistic regression:
```{r}
logreg_tau_file <- file.path("..", "data", "logistic_regression_tau.csv")

if (!use_cache | !file.exists(logreg_tau_file)) {
  
  lr_tau <- future_map_dfr(n_windows, function (n_w) {
    
    d_windows <- copy(d_last)
    
    # Split the data into windows
    if (n_w == 1) {
      d_windows[, window := 1]
    } else {
      d_windows[, window := cut(log(time_between), breaks = n_w, labels = FALSE)]
    }
    
    d_windows_split <- split(d_windows, d_windows$window)
    
    # Within each quantile, perform logistic regression
    lr_nw <- imap_dfr(d_windows_split, function (window, n) {
      
      window[, sequence := 1:.N]
      d_window <- d_f[window[, .(id, window, sequence)], on = .(id)]
      
      d_seq_list <- generate_seq_list(d_window)
  
      correct <- map_int(d_seq_list, ~.$correct)
      
      ac <- map_dbl(d_seq_list, function (x) {
          activation(x$time_within, x$time_between, model_params$h, model_params$decay)
      })
      
      m <- glm(correct ~ 1 + offset((1/model_params$s) * ac),
                 family = binomial)
      tau <- - coef(m)[[1]] * model_params$s
    
      return (list(n_windows = n_w, window = n, tau = tau))
    })
    
    return (lr_nw)  
  }, .progress = interactive())
  
  setDT(lr_tau)
  fwrite(lr_tau, logreg_tau_file)
}

lr_tau <- fread(logreg_tau_file)
```


### Short intervals only
For comparison, find the best threshold for reasonably short intervals: 0-10 minutes.
```{r}
logreg_tau_short_file <- file.path("..", "data", "logistic_regression_tau_short.csv")

if (!use_cache | !file.exists(logreg_tau_short_file)) {
  
  d_short <- copy(d_last)
  d_short <- d_short[time_between <= 10*60]
  d_short[, sequence := 1:.N]
  
  d_short <- d_f[d_short[, .(id, sequence)], on = .(id)]
  d_short[, window := 1]
  
  d_seq_list <- generate_seq_list(d_short)
  
  correct <- map_int(d_seq_list, ~.$correct)
  
  ac <- map_dbl(d_seq_list, function (x) {
    activation(x$time_within, x$time_between, model_params$h, model_params$decay)
  })
  
  m <- glm(correct ~ 1 + offset((1/model_params$s) * ac),
           family = binomial)
  tau_short <- - coef(m)[[1]] * model_params$s
  
  tau_short <- as.data.table(tau_short)
  fwrite(tau_short, logreg_tau_short_file)
}

tau_short <- fread(logreg_tau_short_file)
```

## Optimal activation

Find the optimal activation per window using logistic regression:
```{r}
logreg_activation_file <- file.path("..", "data", "logistic_regression_activation.csv")

if (!use_cache | !file.exists(logreg_activation_file)) {
  
  lr_ac <- future_map_dfr(n_windows, function (n_w) {
    
    d_windows <- copy(d_last)
    
    # Split the data into windows
    if (n_w == 1) {
      d_windows[, window := 1]
    } else {
      d_windows[, window := cut(log(time_between), breaks = n_w, labels = FALSE)]
    }

    d_windows_split <- split(d_windows, d_windows$window)
    
    # Find the appropriate tau value
    window_1 <- d_windows_split[[1]]
    window_1[, sequence := 1:.N]
    d_window_1 <- d_f[window_1[, .(id, window, sequence)], on = .(id)]
    window_1_seq_list <- generate_seq_list(d_window_1)
    correct <- map_int(window_1_seq_list, ~.$correct)
    
    ac <- map_dbl(window_1_seq_list, function (x) {
      activation(x$time_within, x$time_between, model_params$h, model_params$decay)
    })
    
    m <- glm(correct ~ 1 + offset((1/model_params$s) * ac),
             family = binomial)
    tau <- - coef(m)[[1]] * model_params$s
    
    
    # Within each quantile, perform logistic regression to find A
    lr_nw <- imap_dfr(d_windows_split, function (window, n) {
      
      window[, sequence := 1:.N]
      d_window <- d_f[window[, .(id, window, sequence)], on = .(id)]
      
      d_seq_list <- generate_seq_list(d_window)
      
      correct <- map_int(d_seq_list, ~.$correct)
      
      tau_fixed <- rep(tau, length(correct))
      
      m <- glm(correct ~ 1 + offset((-1/model_params$s) * tau_fixed),
               family = binomial)
      
      ac <- coef(m)[[1]] * model_params$s
      
      return (list(n_windows = n_w, window = n, tau = tau, activation = ac))
    })
    
    return (lr_nw)
    
  }, .progress = interactive())
  
  setDT(lr_ac)
  fwrite(lr_ac, logreg_activation_file)
}

lr_ac <- fread(logreg_activation_file)
```


## Optimal decay

Using the optimal activation values determined in the previous step, do a binary search to find the associated decay for each learning sequence:
```{r}
bs_d_indiv_file <- file.path("..", "data", "binary_search_indiv_d.csv")

if (!use_cache | !file.exists(bs_d_indiv_file)) {
  
  bs_d_indiv <- future_map_dfr(n_windows, function (n_w) {
    
    d_windows <- copy(d_last)
    
    # Split the data into windows
    if (n_w == 1) {
      d_windows[, window := 1]
    } else {
      d_windows[, window := cut(log(time_between), breaks = n_w, labels = FALSE)]
    }

    d_windows_split <- split(d_windows, d_windows$window)
    
    # Within each quantile, use binary search to find d from A
    d_nw <- imap_dfr(d_windows_split, function (window, n) {
      
      window[, sequence := 1:.N]
      d_window <- d_f[window[, .(id, window, sequence)], on = .(id)]
      
      ac_window <- lr_ac[n_windows == n_w & window == n, activation]
      
      d_seq_list <- generate_seq_list(d_window)
      
      d_bs <- map_dfr(d_seq_list, function (x) {
        
        d_i <- 1
        d_upper <- 2
        d_lower <- 0
        
        # Binary search
        for (i in 1:100) {
          ac <- activation(x$time_within, x$time_between, model_params$h, d_i)
          
          ac_diff <- ac - ac_window
          
          if (ac_diff > 0) { # Predicted activation too high, so d is too small
            d_lower <- d_i
          } else { # Predicted activation too low, so d is too large
            d_upper <- d_i
          }
          
          d_i <- (d_lower + d_upper) / 2
          
        }
        
        return(list(n_windows = n_w, window = n, id = x$id, d = d_i))
        
      })
      
      return (d_bs)

    })
    
    return (d_nw)
    
  }, .progress = interactive())
  
  setDT(bs_d_indiv)
  fwrite(bs_d_indiv, bs_d_indiv_file)
}

bs_d_indiv <- fread(bs_d_indiv_file)
```


## Optimal scaling factor h

In the same way, do a binary search to find the scaling factor for each learning sequence, based on the optimal activation:
```{r}
bs_h_indiv_file <- file.path("..", "data", "binary_search_indiv_h.csv")

if (!use_cache | !file.exists(bs_h_indiv_file)) {
  
  bs_h_indiv <- future_map_dfr(n_windows, function (n_w) {
    
    d_windows <- copy(d_last)
    
    # Split the data into windows
    if (n_w == 1) {
      d_windows[, window := 1]
    } else {
      d_windows[, window := cut(log(time_between), breaks = n_w, labels = FALSE)]
    }
    
    d_windows_split <- split(d_windows, d_windows$window)
    
    # Within each quantile, use binary search to find h from A
    h_nw <- imap_dfr(d_windows_split, function (window, n) {
      
      window[, sequence := 1:.N]
      d_window <- d_f[window[, .(id, window, sequence)], on = .(id)]
      
      ac_window <- lr_ac[n_windows == n_w & window == n, activation]
      
      d_seq_list <- generate_seq_list(d_window)
      
      h_bs <- map_dfr(d_seq_list, function (x) {
        
        h_i <- .5
        h_upper <- 1
        h_lower <- 0
        
        # Binary search
        for (i in 1:100) {
          ac <- activation(x$time_within, x$time_between, h_i, model_params$decay)
          
          ac_diff <- ac - ac_window
          
          if (ac_diff > 0) { # Predicted activation too high, so h is too small
            h_lower <- h_i
          } else { # Predicted activation too low, so h is too large
            h_upper <- h_i
          }
          
          h_i <- (h_lower + h_upper) / 2
          
        }
        
        return(list(n_windows = n_w, window = n, id = x$id, h = h_i))
        
      })
      
      return (h_bs)
      
    })
    
    return (h_nw)
    
  }, .progress = interactive())
  
  setDT(bs_h_indiv)
  fwrite(bs_h_indiv, bs_h_indiv_file)
}

bs_h_indiv <- fread(bs_h_indiv_file)
```